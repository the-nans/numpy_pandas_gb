{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQtiPPhrOA3I"
   },
   "source": [
    "# Обучение с учителем в Scikit-learn - практическое задание\n",
    "**Задание 1**\n",
    "\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "\n",
    "\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "01GLAtjROA3L"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "data = boston['data']\n",
    "feat_names = boston['feature_names']\n",
    "target = boston['target']\n",
    "\n",
    "X = pd.DataFrame(data, columns=feat_names)\n",
    "y = pd.DataFrame(target, columns=[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpA1j1BIOA3S"
   },
   "source": [
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "\n",
    "\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "\n",
    "\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "\n",
    "\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CH8CW4iwOA3j",
    "outputId": "9caec306-c3e1-43ec-f96a-75a082ad4e15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484974"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar0pbMPNOA3w"
   },
   "source": [
    "**Задание 2**\n",
    "\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "\n",
    "\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "\n",
    "\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "\n",
    "\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMY2jMEHOA3w",
    "outputId": "34b68c3f-1ea5-428b-8136-e57abe83729c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753740319947332"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=100)\n",
    "model.fit(X_train, y_train.values[:, 0])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2_score(y_test, y_pred)\n",
    "\n",
    "# Чем ближе R2 по модулю к единице, тем лучшие результаты даёт модель. В данном случае RandomForestRegressor дал ощутимо лучшие результаты чем линейная модель. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlghDYGOyvcp"
   },
   "source": [
    "**Задание 3**\n",
    "\n",
    "Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_.\n",
    "\n",
    "С помощью этого атрибута найдите сумму всех показателей важности, установите, какие два признака показывают наибольшую важность.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEoNJhOYy-Jh",
    "outputId": "d9a99f0a-6a4c-437f-df66-4eea0fafa892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сумма всех важностей признаков равна 1.0, два наиболее важных признака - LSTAT=0.4246675610352027 и RM=0.39207178852027813\n"
     ]
    }
   ],
   "source": [
    "# help(RandomForestRegressor)\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X.columns, model.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair\n",
    "imps = model.feature_importances_ \n",
    "sort_feats_vals = sorted(feats.values())\n",
    "max_imp_feats = [sorted(feats.values())[-1], sorted(feats.values())[-2]]\n",
    "print(f\"Сумма всех важностей признаков равна {sum(imps)}, два наиболее важных признака - {list(feats.keys())[list(feats.values()).index(max_imp_feats[0])]}={max_imp_feats[0]} и {list(feats.keys())[list(feats.values()).index(max_imp_feats[1])]}={max_imp_feats[1]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXClJI1qO36P"
   },
   "source": [
    "**Задание 4**\n",
    "\n",
    "Решаить задачу классификации транзакций на мошеннические и приличные методом вычисления кривой ROC. Этот метод подходит для несбалансированных датасетов(таких как наш).\n",
    "\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "suK9s9Z3PYy8",
    "outputId": "f14bd0ed-27d2-4ea6-bade-86766463321f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv(\"cardfraud.csv\",sep=\",\")\n",
    "df['Class'].value_counts()  # мошеннических транзакций на три порядка меньше чем законных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "# np.info(df) не ожидала такой штуки, но оставлю её тут. Она прикольная \n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотрите первые 10 строк датафрейма df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>1.341262</td>\n",
       "      <td>0.359894</td>\n",
       "      <td>-0.358091</td>\n",
       "      <td>-0.137134</td>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>0.068653</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>-1.416907</td>\n",
       "      <td>-0.153826</td>\n",
       "      <td>-0.751063</td>\n",
       "      <td>0.167372</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.443587</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.611987</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>-0.219633</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>-0.619468</td>\n",
       "      <td>0.291474</td>\n",
       "      <td>1.757964</td>\n",
       "      <td>-1.323865</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>-0.076127</td>\n",
       "      <td>-1.222127</td>\n",
       "      <td>-0.358222</td>\n",
       "      <td>0.324505</td>\n",
       "      <td>-0.156742</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>-0.705117</td>\n",
       "      <td>-0.110452</td>\n",
       "      <td>-0.286254</td>\n",
       "      <td>0.074355</td>\n",
       "      <td>-0.328783</td>\n",
       "      <td>-0.210077</td>\n",
       "      <td>-0.499768</td>\n",
       "      <td>0.118765</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>1.017614</td>\n",
       "      <td>0.836390</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>-0.443523</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.739453</td>\n",
       "      <td>-0.540980</td>\n",
       "      <td>0.476677</td>\n",
       "      <td>0.451773</td>\n",
       "      <td>0.203711</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n",
       "6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n",
       "7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n",
       "8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n",
       "9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n",
       "6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n",
       "7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n",
       "8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n",
       "9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n",
       "6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n",
       "7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n",
       "8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n",
       "9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  \n",
       "5    3.67      0  \n",
       "6    4.99      0  \n",
       "7   40.80      0  \n",
       "8   93.20      0  \n",
       "9    3.68      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "\n",
    "Просмотрите информацию о их форме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (199364, 30)\n",
      "X_test shape (85443, 30)\n",
      "y_train shape (199364,)\n",
      "y_test shape (85443,)\n"
     ]
    }
   ],
   "source": [
    "X=df.drop('Class', axis=1)   #Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "\n",
    "y=pd.Series(df['Class']) #Создайте объект Series под названием y из столбца Class.\n",
    "\n",
    "#Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, \n",
    "# используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "#Просмотрите информацию о их форме.\n",
    "for i, k in {'X_train' : X_train, \"X_test\" : X_test, \"y_train\" : y_train,  \"y_test\" : y_test}.items():\n",
    "    print(f\"{i} shape {k.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "\n",
    "Обучите модель(может занять несколько минут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid=[{'max_depth': array([4, 5, 6]),\n",
       "                          'max_features': array([3, 4]),\n",
       "                          'n_estimators': [10, 15]}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3)\n",
    "\n",
    "clf.fit(X_train, y_train) # обучите модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462664156037156"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "y_predict_proba=clf.predict_proba(X_test) \n",
    "\n",
    "#Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и \n",
    "#запишите в массив y_pred_proba.\n",
    "y_predict_proba = y_predict_proba[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# бонус - roc-curve для данных\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_predict_proba, pos_label=1)\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='dashed')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "\n",
    "plt.show()   #почти половина квадрата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TVZzApDvOA3i",
    "jWvM8H16OA3k",
    "C1fJYf_8OA3q",
    "Ar0pbMPNOA3w",
    "QpPhhcRROA3z",
    "YsO9esuJOA36",
    "iUO420mHOA39",
    "Y5pOXYCIOA4J",
    "tOJoF25COA4N",
    "Si24pRe7OA4T",
    "2_BKWozoOA4V",
    "LHl4mfwUOA4X",
    "98nSHlCtOA4a",
    "S2NctbPLOA4d",
    "2P-cI3YkOA4f",
    "eh5Kdvz3OA4h",
    "V2YvZ8CjOA4q",
    "TQZHch1nOA4t",
    "NxWBIX8KOA4u"
   ],
   "name": "Обучение с учителем в Scikit-learn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
